import requests
import pandas as pd
import os
import logging
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- CONFIGURATION ---
BASE_DIR = r"C:\RiskPortal\GetRepos"  # Input & Output Directory
INPUT_FILE = os.path.join(BASE_DIR, "CI.xlsx")  # Excel file containing SPK column
OUTPUT_FILE = os.path.join(BASE_DIR, "Bitbucket_Repositories.xlsx")  # Output file
LOG_FILE = os.path.join(BASE_DIR, "bitbucket_fetch.log")  # Log file

# Bitbucket API Credentials
BITBUCKET_URL = "https://api.bitbucket.org/2.0/repositories"
USERNAME = "your_username"  # Replace with your Bitbucket username
APP_PASSWORD = "your_app_password"  # Replace with your Bitbucket app password

# --- SETUP LOGGING ---
logging.basicConfig(filename=LOG_FILE, level=logging.INFO, 
                    format="%(asctime)s - %(levelname)s - %(message)s")

# --- FUNCTION TO VALIDATE API ACCESS ---
def validate_api_access():
    """Validates user access to the Bitbucket API before making bulk requests."""
    test_url = f"{BITBUCKET_URL}?pagelen=1"
    try:
        response = requests.get(test_url, auth=(USERNAME, APP_PASSWORD))
        if response.status_code == 200:
            logging.info("API validation successful.")
            print("✅ API access validated successfully.")
            return True
        else:
            logging.error(f"API validation failed: {response.status_code} - {response.text}")
            print(f"❌ API validation failed. Check {LOG_FILE} for details.")
            return False
    except requests.exceptions.RequestException as e:
        logging.error(f"API validation error: {e}")
        print(f"❌ API validation error. Check {LOG_FILE} for details.")
        return False

# --- FUNCTION TO FETCH REPOSITORIES ---
def fetch_repositories(spk):
    """
    Fetches all repositories for a given SPK (project key) from Bitbucket API.
    Handles pagination to get all results.
    """
    url = f"{BITBUCKET_URL}?q=project.key=\"{spk}\"&pagelen=100"
    repositories = []
    failure_count = 0

    while url:
        try:
            response = requests.get(url, auth=(USERNAME, APP_PASSWORD))
            response.raise_for_status()  # Raise an error for bad responses
            data = response.json()

            # Extract repository information
            for repo in data.get('values', []):
                repositories.append({
                    "Project Key": spk,
                    "Repo Name": repo.get("name"),
                    "Repo Slug": repo.get("slug"),
                    "Repo ID": repo.get("uuid"),
                    "SCM Type": repo.get("scm"),
                    "State": repo.get("state"),
                    "Default Branch": repo.get("mainbranch", {}).get("name", "N/A"),
                    "Last Updated": repo.get("updated_on"),
                    "Size (Bytes)": repo.get("size"),
                    "Language": repo.get("language", "N/A"),
                    "Forks": repo.get("forks_count", "N/A"),
                    "Watchers": repo.get("watchers_count", "N/A"),
                    "Clone URL (HTTPS)": next((link['href'] for link in repo.get('links', {}).get('clone', []) if link['name'] == 'https'), "N/A"),
                    "Repo URL": repo.get("links", {}).get("html", {}).get("href", "N/A"),
                })

            # Check for pagination
            url = data.get("next", None)
            time.sleep(1)  # Respect API rate limits

        except requests.exceptions.RequestException as e:
            failure_count += 1
            logging.error(f"Failed to fetch repositories for SPK: {spk} - {e}")

    return repositories, failure_count

# --- MAIN SCRIPT ---
def main():
    if not validate_api_access():
        return  # Stop execution if API validation fails

    try:
        # Load SPK column from Excel
        df = pd.read_excel(INPUT_FILE, usecols=["SPK"])
        spk_list = df["SPK"].dropna().unique()  # Remove duplicates & NaN

        all_repos = []
        total_failures = 0

        # Use ThreadPoolExecutor for parallel execution
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_spk = {executor.submit(fetch_repositories, spk): spk for spk in spk_list}

            for future in as_completed(future_to_spk):
                spk = future_to_spk[future]
                try:
                    repos, failures = future.result()
                    all_repos.extend(repos)
                    total_failures += failures
                    print(f"✅ Completed SPK: {spk} | Repos: {len(repos)} | Failures: {failures}")
                except Exception as e:
                    logging.error(f"Unexpected error for SPK {spk}: {e}")
                    total_failures += 1

        # Save results to Excel
        if all_repos:
            output_df = pd.DataFrame(all_repos)
            output_df.to_excel(OUTPUT_FILE, index=False)
            print(f"✅ Repository data saved to {OUTPUT_FILE}")

        # Log total failures
        logging.info(f"Total failures: {total_failures}")
        print(f"⚠️ Total failures logged: {total_failures}")

    except Exception as e:
        logging.error(f"Unexpected error in main: {e}")
        print("❌ An error occurred. Check the log file for details.")

if __name__ == "__main__":
    main()

import time
import random
import pandas as pd
from exchangelib import Credentials, Account

# Set your Exchange credentials
EMAIL = "your.email@company.com"
PASSWORD = "your_password"

# Log file for skipped entries
SKIP_LOG_FILE = "C:\\Users\\Public\\GAL_Skipped_Entries.log"

# ‚úÖ Set to track processed emails (Avoids duplicates)
processed_emails = set()

# Connect to Exchange
try:
    print("Connecting to Exchange...")
    credentials = Credentials(EMAIL, PASSWORD)
    account = Account(EMAIL, credentials=credentials, autodiscover=True)
    print("‚úÖ Connected to Exchange successfully!")

except Exception as e:
    print(f"‚ùå ERROR: Unable to connect to Exchange. {e}")
    exit()

# ‚úÖ Function to log skipped entries with reason
def log_skipped(reason, user_data="N/A"):
    message = f"‚ö†Ô∏è Skipping entry: {reason} | Data: {user_data}"
    print(message)  # Print to console
    with open(SKIP_LOG_FILE, "a", encoding="utf-8") as log_file:
        log_file.write(message + "\n")  # Log to file

# ‚úÖ Function to fetch all contacts using `FindPeople`
def fetch_contacts(account, page_size=100):
    contacts = []
    offset = 0  # ‚úÖ Offset for pagination

    while True:
        print(f"üìå Fetching batch {offset // page_size + 1} (Offset: {offset}) ...")
        
        # ‚úÖ Add a delay to prevent server overload
        time.sleep(random.uniform(0.5, 2))

        # ‚úÖ Fetch contacts in paginated manner
        items = account.contacts.filter().order_by('display_name')[offset:offset + page_size]
        
        # ‚úÖ Stop if no more records are found
        if not items:
            break

        for item in items:
            email = item.email_addresses[0] if item.email_addresses else "N/A"

            # ‚úÖ Skip duplicate records
            if email in processed_emails:
                continue
            processed_emails.add(email)

            # ‚úÖ Extract all required fields
            display_name = item.display_name if item.display_name else "N/A"
            job_title = item.job_title if item.job_title else "N/A"
            department = item.department if item.department else "N/A"
            city = item.physical_addresses[0].city if item.physical_addresses else "N/A"
            country = item.physical_addresses[0].country if item.physical_addresses else "N/A"
            zip_code = item.physical_addresses[0].zipcode if item.physical_addresses else "N/A"
            manager_name = item.manager if item.manager else "N/A"

            contacts.append([
                display_name, email, job_title, department, city, country, zip_code, manager_name
            ])

        # ‚úÖ Move to the next batch
        offset += page_size

    return contacts

# Fetch all contacts using pagination
start_time = time.time()
contacts = fetch_contacts(account)

# Convert to DataFrame
df = pd.DataFrame(contacts, columns=[
    "Display Name", "Email", "Job Title", "Department",
    "City", "Country", "Zip Code", "Manager Name"
])

# Save to CSV
output_file = "C:\\Users\\Public\\GAL_FindPeople_Contacts.csv"
df.to_csv(output_file, index=False, encoding="utf-8")

# Print execution summary
elapsed_time = time.time() - start_time
print(f"\n‚úÖ Export completed successfully! Data saved to {output_file}")
print(f"üîπ Total Valid Records Processed: {len(contacts)}")
print(f"‚è≥ Total Execution Time: {elapsed_time:.2f} seconds")
print(f"‚ö†Ô∏è Skipped entries logged in: {SKIP_LOG_FILE}")

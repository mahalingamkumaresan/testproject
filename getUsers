import concurrent.futures
from exchangelib import Credentials, Account
import pandas as pd
import time
import string
import re  # Used to extract Standard ID

# Set your Exchange credentials
EMAIL = "your.email@company.com"
PASSWORD = "your_password"

# Log file for skipped entries
SKIP_LOG_FILE = "C:\\Users\\Public\\GAL_Skipped_Entries.log"

# Connect to Exchange
try:
    print("Connecting to Exchange...")
    credentials = Credentials(EMAIL, PASSWORD)
    account = Account(EMAIL, credentials=credentials, autodiscover=True)
    print("✅ Connected to Exchange successfully!")

except Exception as e:
    print(f"❌ ERROR: Unable to connect to Exchange. {e}")
    exit()

# Character set to iterate over GAL efficiently
search_prefixes = list(string.ascii_uppercase + "0123456789@._")

# Function to extract Standard ID from name format "LastName, FirstName STANDARDID"
def extract_standard_id(name):
    if name and isinstance(name, str):
        match = re.search(r'\b(\w+)$', name)  # Extracts last word (Standard ID)
        return match.group(1) if match else "N/A"
    return "N/A"

# ✅ Function to log skipped entries with reason
def log_skipped(reason, query, user_data="N/A"):
    message = f"⚠️ Skipping entry for {query}: {reason} | Data: {user_data}"
    print(message)  # Print to console
    with open(SKIP_LOG_FILE, "a", encoding="utf-8") as log_file:
        log_file.write(message + "\n")  # Log to file

# ✅ Function to fetch contacts while handling errors properly
def fetch_contacts(prefix, depth=1):
    """Recursively fetch contacts by refining the search query if needed."""
    try:
        contacts = []
        query = prefix + "*"

        print(f"📌 Fetching contacts starting with: {query} ...")
        resolved_names = account.protocol.resolve_names(query, return_full_contact_data=True)

        if not resolved_names:
            return []

        for user in resolved_names:
            if isinstance(user, tuple) and len(user) >= 2:  # ✅ Normal Case (Tuple User)
                job_title = str(user[1].job_title).strip() if hasattr(user[1], "job_title") and user[1].job_title else "N/A"

                if job_title == "N/A":
                    log_skipped("Job Title is empty", query, user[1].display_name)
                    continue  

                email = user[0].email_address if hasattr(user[0], "email_address") else "N/A"
                display_name = user[1].display_name if hasattr(user[1], "display_name") else "N/A"
                standard_id = extract_standard_id(user[0].name) if hasattr(user[0], "name") else "N/A"

                department = str(user[1].department).strip() if hasattr(user[1], "department") and user[1].department else "N/A"

                city, country, zip_code = "N/A", "N/A", "N/A"
                if hasattr(user[1], "physical_addresses") and isinstance(user[1].physical_addresses, tuple) and len(user[1].physical_addresses) > 0:
                    address = user[1].physical_addresses[0]
                    city = str(address.city).strip() if hasattr(address, "city") and address.city else "N/A"
                    country = str(address.country).strip() if hasattr(address, "country") and address.country else "N/A"
                    zip_code = str(address.zipcode).strip() if hasattr(address, "zipcode") and address.zipcode else "N/A"

                manager_name = str(user[1].manager).strip() if hasattr(user[1], "manager") and user[1].manager else "N/A"
                manager_standard_id = extract_standard_id(manager_name)

                direct_reports_count = len(user[1].direct_reports) if hasattr(user[1], "direct_reports") and isinstance(user[1].direct_reports, tuple) else 0

            else:  # ✅ Handle Non-Tuple Users
                print(f"⚠️ User is not a tuple. Processing with limited data: {user}")
                email = user.email_address if hasattr(user, "email_address") else "N/A"
                display_name = user.name if hasattr(user, "name") else "N/A"
                standard_id = extract_standard_id(user.name) if hasattr(user, "name") else "N/A"

                # ✅ Set all other fields to "N/A"
                job_title = department = city = country = zip_code = manager_name = manager_standard_id = "N/A"
                direct_reports_count = 0

            contacts.append([
                display_name, standard_id, email, job_title, department,
                city, country, zip_code, manager_name, manager_standard_id, direct_reports_count
            ])

        print(f"✅ Completed: {query} - {len(contacts)} valid contacts (Job Title Required)")

        if len(resolved_names) == 100 and depth < 3:
            for letter in string.ascii_uppercase:
                contacts += fetch_contacts(prefix + letter, depth + 1)
            for digit in "0123456789":
                contacts += fetch_contacts(prefix + digit, depth + 1)

        return contacts

    except Exception as e:
        log_skipped(f"Unexpected error: {e}", prefix)
        return []

# Multithreading Execution
contacts = []
start_time = time.time()

with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
    futures = [executor.submit(fetch_contacts, prefix) for prefix in search_prefixes]

for future in concurrent.futures.as_completed(futures):
    contacts.extend(future.result())

# Convert to DataFrame
df = pd.DataFrame(contacts, columns=[
    "Display Name", "Standard ID", "Email", "Job Title", "Department",
    "City", "Country", "Zip Code", "Manager Name", "Manager Standard ID", "Direct Reports Count"
])

# Save to CSV
output_file = "C:\\Users\\Public\\GAL_EWS_Contacts.csv"
df.to_csv(output_file, index=False, encoding="utf-8")

# Print execution summary

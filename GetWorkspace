import requests
import pandas as pd
import os
import logging
import time
import urllib3
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- CONFIGURATION ---
BASE_DIR = r"C:\RiskPortal\GetRepos"  # Base directory for input/output
INPUT_FILE = os.path.join(BASE_DIR, "CI.xlsx")  # Input file containing SPK column
OUTPUT_FILE = os.path.join(BASE_DIR, "Bitbucket_Repositories.xlsx")  # Output Excel file
LOG_FILE = os.path.join(BASE_DIR, "bitbucket_fetch.log")  # Log file

# Bitbucket API Credentials
BITBUCKET_URL = "https://api.bitbucket.org/2.0"
USERNAME = "your_username"  # Replace with Bitbucket username
APP_PASSWORD = "your_app_password"  # Replace with Bitbucket app password

# --- SUPPRESS WARNINGS ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- SETUP LOGGING ---
logging.basicConfig(filename=LOG_FILE, level=logging.INFO, 
                    format="%(asctime)s - %(levelname)s - %(message)s")

# --- FUNCTION TO VALIDATE API ACCESS ---
def validate_api_access():
    """Validates API access before making bulk repository requests."""
    test_url = f"{BITBUCKET_URL}/projects?pagelen=1"
    try:
        response = requests.get(test_url, auth=(USERNAME, APP_PASSWORD), verify=False)
        if response.status_code == 200:
            logging.info("✅ API validation successful.")
            print("✅ API access validated successfully.")
            return True
        else:
            logging.error(f"❌ API validation failed: {response.status_code} - {response.text}")
            print(f"❌ API validation failed. Check {LOG_FILE} for details.")
            return False
    except requests.exceptions.RequestException as e:
        logging.error(f"❌ API validation error: {e}")
        print(f"❌ API validation error. Check {LOG_FILE} for details.")
        return False

# --- FUNCTION TO FETCH REPOSITORIES ---
def fetch_repositories(spk):
    """
    Fetches all repositories for a given SPK (project key) from Bitbucket API.
    Handles pagination using `/projects/{spk}/repos?limit=1000`.
    """
    url = f"{BITBUCKET_URL}/projects/{spk}/repos?limit=1000"
    repositories = []
    failure_count = 0

    while url:
        try:
            response = requests.get(url, auth=(USERNAME, APP_PASSWORD), verify=False)
            response.raise_for_status()  # Raise an error if request fails
            data = response.json()

            # Extract repository information
            for repo in data.get('values', []):
                repositories.append({
                    "Project Key": spk,
                    "Repo Name": repo.get("name"),
                    "Repo Slug": repo.get("slug"),
                    "Repo ID": repo.get("uuid"),
                    "SCM Type": repo.get("scm"),
                    "State": repo.get("state"),
                    "Default Branch": repo.get("mainbranch", {}).get("name", "N/A"),
                    "Last Updated": repo.get("updated_on"),
                    "Size (Bytes)": repo.get("size"),
                    "Language": repo.get("language", "N/A"),
                    "Forks": repo.get("forks_count", "N/A"),
                    "Watchers": repo.get("watchers_count", "N/A"),
                    "Clone URL (HTTPS)": next((link['href'] for link in repo.get('links', {}).get('clone', []) if link['name'] == 'https'), "N/A"),
                    "Repo URL": repo.get("links", {}).get("html", {}).get("href", "N/A"),
                })

            # Handle pagination
            url = data.get("next", None)
            time.sleep(1)  # Respect API rate limits

        except requests.exceptions.RequestException as e:
            failure_count += 1
            logging.error(f"❌ Failed to fetch repositories for SPK: {spk} - {e}")
            break

    return repositories, failure_count

# --- MAIN SCRIPT ---
def main():
    if not validate_api_access():
        return  # Stop execution if API validation fails

    try:
        # Load SPK column from Excel
        df = pd.read_excel(INPUT_FILE, usecols=["SPK"])
        spk_list = df["SPK"].dropna().unique()  # Remove duplicates & NaN

        all_repos = []
        total_failures = 0

        # Use ThreadPoolExecutor for parallel execution
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_spk = {executor.submit(fetch_repositories, spk): spk for spk in spk_list}

            for future in as_completed(future_to_spk):
                spk = future_to_spk[future]
                try:
                    repos, failures = future.result()
                    all_repos.extend(repos)
                    total_failures += failures
                    print(f"✅ Completed SPK: {spk} | Repos: {len(repos)} | Failures: {failures}")
                except Exception as e:
                    logging.error(f"❌ Unexpected error for SPK {spk}: {e}")
                    total_failures += 1

        # Save results to Excel
        if all_repos:
            output_df = pd.DataFrame(all_repos)
            output_df.to_excel(OUTPUT_FILE, index=False)
            print(f"✅ Repository data saved to {OUTPUT_FILE}")

        # Log total failures
        logging.info(f"⚠️ Total failures: {total_failures}")
        print(f"⚠️ Total failures logged: {total_failures}")

    except Exception as e:
        logging.error(f"❌ Unexpected error in main: {e}")
        print("❌ An error occurred. Check the log file for details.")

if __name__ == "__main__":
    main()
